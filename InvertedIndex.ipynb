{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "xiB1P8D7Afzu",
    "outputId": "30849d4c-3821-4e1c-dde2-201780219fdf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Nuzha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "sw = stopwords.words(\"english\")\n",
    "import snowballstemmer\n",
    "from itertools import islice\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "zA2TnU_QAf0W"
   },
   "outputs": [],
   "source": [
    "# PREPROCESSING TEXT\n",
    "def ParseText(text):\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "    text = text.lower()\n",
    "    text = \" \".join(text.split())\n",
    "\n",
    "    tokens = text.split(\" \")\n",
    "    tokens[:] = [word for word in tokens if word not in sw]\n",
    "\n",
    "    tokens[:] = [re.sub(\"[^a-zA-Z]\", '', word) for word in tokens]\n",
    "    tokens = list(filter(None, tokens))\n",
    "\n",
    "    stemmer = snowballstemmer.stemmer('english')\n",
    "    tokens = stemmer.stemWords(tokens)\n",
    "    tokens = [word for word in tokens if len(word) > 1]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "4yZj-gOMAf0Y",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# CREATE INVERTED INDEX\n",
    "def CreateInvertedIndex(docs, path):\n",
    "    index = {}\n",
    "    if doc_id == 0:\n",
    "        file = open(\"docInfo.txt\", \"x\")\n",
    "    else:\n",
    "        file = open(\"docInfo.txt\", \"a+\")\n",
    "    id_ = doc_id\n",
    "    for doc in docs:\n",
    "        docinfo = []\n",
    "        id_ = id_ + 1\n",
    "        docinfo.append(id_)\n",
    "        docinfo.append(doc)\n",
    "        docinfo.append(os.stat(path + doc).st_size)\n",
    "        info = [str(int) for int in docinfo]\n",
    "        info = \",\".join(info)\n",
    "        file.write(info + \"\\n\")\n",
    "        name, extension = os.path.splitext(doc)\n",
    "        #print(doc)\n",
    "        #print (name, extension)\n",
    "        if extension == \".txt\":\n",
    "            continue\n",
    "        try:\n",
    "            html = open(path + doc).read()\n",
    "        except:\n",
    "            continue\n",
    "        soup = BeautifulSoup(html, features=\"html.parser\")\n",
    "\n",
    "        for script in soup([\"script\", \"style\"]):\n",
    "            script.extract()\n",
    "\n",
    "        # get text\n",
    "        try:\n",
    "            text = soup.body.get_text(\" \")\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        # remove extra lines and spaces\n",
    "        lines = (line.strip() for line in text.splitlines())\n",
    "        chunks = (phrase.strip() for line in lines for phrase in line.split(\"  \"))\n",
    "        text = '\\n'.join(chunk for chunk in chunks if chunk)\n",
    "\n",
    "        tokens = ParseText(text)\n",
    "        pos = 0\n",
    "        for token in tokens:\n",
    "            posting = index.get(token, None)\n",
    "            if posting is None:      \n",
    "                posting = {id_ : [1, pos]}\n",
    "            else:    \n",
    "                if id_ not in posting: # You can also keep TF here\n",
    "                    #posting.append(doc) \n",
    "                    posting[id_] = [1, pos]\n",
    "                else:\n",
    "                    posting[id_][0] = posting[id_][0] + 1\n",
    "                    #print(posting[doc])\n",
    "                    posting[id_].append(pos)\n",
    "\n",
    "            index[token]= posting\n",
    "            pos = pos + 1\n",
    "    file.close()\n",
    "    return index, id_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "RWhgRPPmAf0b"
   },
   "outputs": [],
   "source": [
    "# SAVE INDEX TO FILE\n",
    "def createIndexFile(indexfile, posting, index):\n",
    "    p = open(posting, \"x\") #posting list\n",
    "    i = open(indexfile, \"x\") #index\n",
    "\n",
    "    for key, value in index.items():\n",
    "        write = []\n",
    "        write.append(len(index[key]))\n",
    "        prev = 0\n",
    "        for k, v in value.items():\n",
    "            if prev != 0:\n",
    "                write.append(k - prev)\n",
    "            else:\n",
    "                write.append(k)\n",
    "            write.append(len(v))\n",
    "            prev = k\n",
    "            previn = 0\n",
    "            for item in v:\n",
    "                if previn != 0:\n",
    "                    write.append(item-previn)\n",
    "                else:\n",
    "                    write.append(item)\n",
    "                previn = item\n",
    "        #print(\" THIS = \", write)\n",
    "        lol = [str(int) for int in write]\n",
    "        lol = \",\".join(lol)\n",
    "        #print(lol)\n",
    "        a = p.tell()\n",
    "        s = key + \",\" + str(a)\n",
    "        i.write(s + \"\\n\")\n",
    "\n",
    "        p.write(lol+\"\\n\")\n",
    "    p.close()\n",
    "    i.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "J0Ze1EpLAf0d",
    "outputId": "311a61a2-11ac-4a71-ba3b-0bb0050eb872"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1161\n",
      "2266\n"
     ]
    }
   ],
   "source": [
    "# DRIVER CODE\n",
    "doc_id = 0 \n",
    "# get directory\n",
    "path = \"C:\\\\Users\\\\Nuzha\\\\Desktop\\\\corpus1\\\\\" \n",
    "for i in range(3):\n",
    "    docs = os.listdir(path + str(i + 1))\n",
    "    #create index of 1 block at a time\n",
    "    print(doc_id)\n",
    "    index, doc_id = CreateInvertedIndex(docs, path + str(i + 1) + \"\\\\\")\n",
    "    #sort index\n",
    "    index = dict(sorted(index.items(), key=lambda item: item[0]))\n",
    "    #save the index in files\n",
    "    indexfile = 'index_' + str(i + 1) + '_terms.txt'\n",
    "    posting = 'index_' + str(i + 1) + '_postings.txt'\n",
    "    createIndexFile(indexfile, posting, index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "geyXTYu2Af0e"
   },
   "outputs": [],
   "source": [
    "# HELPER FUNCTIONS FOR MERGER\n",
    "def Decode(posting1):\n",
    "    a = 1\n",
    "    prev = 0\n",
    "    posting1[0] = int(posting1[0])\n",
    "    while a < len(posting1):\n",
    "        posting1[a] = int(posting1[a]) + prev\n",
    "        prev = posting1[a]\n",
    "        a = a + 1\n",
    "        b = 0\n",
    "        prev2 = 0\n",
    "        if a == len(posting1):\n",
    "            break\n",
    "        size = int(posting1[a])\n",
    "        posting1[a] = size\n",
    "        a = a + 1\n",
    "        while b < size:\n",
    "            posting1[a] = prev2 + int(posting1[a])\n",
    "            prev2 = posting1[a]\n",
    "            a = a + 1\n",
    "            b = b + 1\n",
    "    \n",
    "    return posting1\n",
    "\n",
    "def MergePostings(posting1, posting2):\n",
    "    size = posting1[0] + posting2[0]\n",
    "    k = 0\n",
    "    index1 = 1\n",
    "    index2 = 1\n",
    "    output_posting = []\n",
    "    output_posting.append(size)\n",
    "    while k < size:\n",
    "        if index1 == len(posting1):\n",
    "            while index2 != len(posting2):\n",
    "                output_posting.append(posting2[index2]) #id\n",
    "                index2 = index2 + 1\n",
    "                pos = posting2[index2] #no. of positions\n",
    "                output_posting.append(posting2[index2])\n",
    "                p = 0\n",
    "                index2 = index2 + 1\n",
    "                while p < pos:\n",
    "                    output_posting.append(posting2[index2])\n",
    "                    p = p + 1\n",
    "                    index2 = index2 + 1\n",
    "            break\n",
    "        elif index2 == len(posting2):\n",
    "            while index1 != len(posting1):\n",
    "                output_posting.append(posting1[index1]) #id\n",
    "                index1 = index1 + 1\n",
    "                pos = posting1[index1] #no. of positions\n",
    "                output_posting.append(posting1[index1])\n",
    "                p = 0\n",
    "                index1 = index1 + 1\n",
    "                while p < pos:\n",
    "                    output_posting.append(posting1[index1])\n",
    "                    p = p + 1\n",
    "                    index1 = index1 + 1\n",
    "            break\n",
    "        if posting1[index1] < posting2[index2]:\n",
    "            output_posting.append(posting1[index1]) #id\n",
    "            index1 = index1 + 1\n",
    "            pos = posting1[index1] #no. of positions\n",
    "            output_posting.append(posting1[index1])\n",
    "            p = 0\n",
    "            index1 = index1 + 1\n",
    "            while p < pos:\n",
    "                output_posting.append(posting1[index1])\n",
    "                p = p + 1\n",
    "                index1 = index1 + 1\n",
    "        elif posting1[index1] > posting2[index2]:\n",
    "            output_posting.append(posting2[index2]) #id\n",
    "            index2 = index2 + 1\n",
    "            pos = posting2[index2] #no. of positions\n",
    "            output_posting.append(posting2[index2])\n",
    "            p = 0\n",
    "            index2 = index2 + 1\n",
    "            while p < pos:\n",
    "                output_posting.append(posting2[index2])\n",
    "                p = p + 1\n",
    "                index2 = index2 + 1\n",
    "        k = k + 1\n",
    "    return output_posting\n",
    "\n",
    "def Encode(output_posting):\n",
    "    a = 1\n",
    "    prev = 0\n",
    "    posting1 = []\n",
    "    posting1.append(output_posting[0])\n",
    "\n",
    "    while a < len(output_posting):\n",
    "        posting1.append(output_posting[a] - prev)\n",
    "        prev = output_posting[a]\n",
    "        a = a + 1\n",
    "        b = 0\n",
    "        prev2 = 0\n",
    "        if a == len(output_posting):\n",
    "            break\n",
    "        size = output_posting[a]\n",
    "        posting1.append(size)\n",
    "        a = a + 1\n",
    "        while b < size:\n",
    "            posting1.append(output_posting[a] - prev2)\n",
    "            prev2 = output_posting[a]\n",
    "            a = a + 1\n",
    "            b = b + 1\n",
    "    return posting1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "BiRXUUUNAf0k"
   },
   "outputs": [],
   "source": [
    "def MergeIndexFiles():\n",
    "\n",
    "    # define the name of the file to read from\n",
    "    output_in = open(\"inverted_index_terms.txt\", \"x\")\n",
    "    output_post = open(\"inverted_index_postings.txt\", \"x\")\n",
    "\n",
    "    p1 = open(\"index_1_postings.txt\", \"r\")\n",
    "    p2 = open(\"index_2_postings.txt\", \"r\")\n",
    "    p3 = open(\"index_3_postings.txt\", \"r\")\n",
    "\n",
    "    index_file1 = open('index_1_terms.txt', 'r')\n",
    "    index_file2 = open('index_2_terms.txt', 'r')\n",
    "    index_file3 = open('index_3_terms.txt', 'r')\n",
    "\n",
    "    # define the number of lines to read\n",
    "    number_of_lines = 50\n",
    "    flag1 = 0\n",
    "    flag2 = 0\n",
    "    flag3 = 0\n",
    "\n",
    "    while True:\n",
    "\n",
    "        if flag1 == 0:\n",
    "            in1 = list(islice(index_file1, number_of_lines))\n",
    "            #print(in1)\n",
    "            i = 0\n",
    "            if not in1:\n",
    "                flag1 = 2\n",
    "            else:\n",
    "                flag1 = 1\n",
    "        if flag2 == 0:\n",
    "            in2 = list(islice(index_file2, number_of_lines))\n",
    "            #print(in2)\n",
    "            j = 0\n",
    "            if not in2:\n",
    "                flag2 = 2\n",
    "            else:\n",
    "                flag2 = 1\n",
    "        if flag3 == 0:\n",
    "            in3 = list(islice(index_file3, number_of_lines))\n",
    "            #print(in2)\n",
    "            k = 0\n",
    "            if not in3:\n",
    "                flag3 = 2\n",
    "            else:\n",
    "                flag3 = 1\n",
    "\n",
    "        if flag1 == 2 and flag2 == 2 and flag3 == 0:\n",
    "            break\n",
    "\n",
    "        if flag1 == 2 and flag3 == 2:\n",
    "            #print(\"here1\")\n",
    "            while j < number_of_lines:\n",
    "                try:\n",
    "                    first2 = in2[j].split(\",\")\n",
    "                except:\n",
    "                    flag2 = 2\n",
    "                    break\n",
    "                getbyte = first2[1]\n",
    "                p2.seek(int(getbyte))\n",
    "                posting = p2.readline()\n",
    "                byte = output_post.tell()\n",
    "                output_post.write(posting)\n",
    "                #print(first2[0] + \",\" + str(byte) + \"\\n\")\n",
    "                output_in.write(first2[0] + \",\" + str(byte) + \"\\n\")\n",
    "                j = j + 1\n",
    "            if flag2 == 2:\n",
    "                break\n",
    "            flag2 = 0\n",
    "\n",
    "        #index file 2 and 3 is finished, so read index 1 file completely\n",
    "        elif flag2 == 2 and flag3 == 2:\n",
    "            #print(\"here2\")\n",
    "            while i < number_of_lines:\n",
    "                try:\n",
    "                    first1 = in1[i].split(\",\")\n",
    "                except:\n",
    "                    flag1 = 2\n",
    "                    break\n",
    "                getbyte = first1[1]\n",
    "                p1.seek(int(getbyte))\n",
    "                posting = p1.readline()\n",
    "                byte = output_post.tell()\n",
    "                output_post.write(posting)\n",
    "                #print(first1[0] + \",\" + str(byte) + \"\\n\")\n",
    "                output_in.write(first1[0] + \",\" + str(byte) + \"\\n\")\n",
    "                i = i + 1\n",
    "            if flag1 == 2:\n",
    "                break\n",
    "            flag1 = 0\n",
    "\n",
    "        elif flag1 == 2 and flag2 == 2:\n",
    "            #print(\"here3\")\n",
    "            while k < number_of_lines:\n",
    "                try:\n",
    "                    first3 = in3[k].split(\",\")\n",
    "                except:\n",
    "                    flag3 = 2\n",
    "                    break\n",
    "                getbyte = first3[1]\n",
    "                p3.seek(int(getbyte))\n",
    "                posting = p3.readline()\n",
    "                byte = output_post.tell()\n",
    "                output_post.write(posting)\n",
    "                #print(first1[0] + \",\" + str(byte) + \"\\n\")\n",
    "                output_in.write(first3[0] + \",\" + str(byte) + \"\\n\")\n",
    "                k = k + 1\n",
    "            if flag3 == 0:\n",
    "                break\n",
    "            flag3 = 0\n",
    "\n",
    "        # if only one file is finished\n",
    "        elif flag3 == 2:\n",
    "            #print(\"here4\")\n",
    "            while(flag1 == 1 and flag2 == 1):\n",
    "                try:\n",
    "                    first1 = in1[i].split(\",\")\n",
    "                except:\n",
    "                    flag1 = 2\n",
    "                    continue\n",
    "                try:\n",
    "                    first2 = in2[j].split(\",\")\n",
    "                except:\n",
    "                    flag2 = 2\n",
    "                    continue\n",
    "\n",
    "                #if current word is same in both files \n",
    "                if first1[0] == first2[0]:\n",
    "                    getbyte = first1[1]\n",
    "                    p1.seek(int(getbyte))\n",
    "                    posting1 = p1.readline()\n",
    "                    posting1 = posting1[0:len(posting1)-1].split(\",\")\n",
    "\n",
    "                    getbyte = first2[1]\n",
    "                    p2.seek(int(getbyte))\n",
    "                    posting2 = p2.readline()\n",
    "                    posting2 = posting2[0:len(posting2)-1].split(\",\")\n",
    "\n",
    "                    posting1 = Decode(posting1)\n",
    "                    posting2 = Decode(posting2)\n",
    "\n",
    "                    output_posting = MergePostings(posting1, posting2)\n",
    "                    \n",
    "                    output_posting = Encode(output_posting)\n",
    "                    \n",
    "                    lol = [str(int) for int in output_posting]\n",
    "                    lol = \",\".join(lol)\n",
    "                    byte = output_post.tell()\n",
    "                    output_post.write(lol + \"\\n\")\n",
    "                    output_in.write(first2[0] + \",\" + str(byte) + \"\\n\")\n",
    "                    i = i + 1\n",
    "                    j = j + 1\n",
    "\n",
    "                elif min(first1[0], first2[0]) == first1[0]:\n",
    "                    getbyte = first1[1]\n",
    "                    p1.seek(int(getbyte))\n",
    "                    posting = p1.readline()\n",
    "                    byte = output_post.tell()\n",
    "                    output_post.write(posting)\n",
    "                    #print(first1[0] + \",\" + str(byte) + \"\\n\")\n",
    "                    output_in.write(first1[0] + \",\" + str(byte) + \"\\n\")\n",
    "                    i = i + 1\n",
    "                else:\n",
    "                    getbyte = first2[1]\n",
    "                    p2.seek(int(getbyte))\n",
    "                \n",
    "                    posting = p2.readline()\n",
    "                    byte = output_post.tell()\n",
    "                    output_post.write(posting)\n",
    "                    #print(first2[0] + \",\" + str(byte) + \"\\n\")\n",
    "                    output_in.write(first2[0] + \",\" + str(byte) + \"\\n\")\n",
    "                    j = j + 1\n",
    "\n",
    "                if i == number_of_lines:\n",
    "                    flag1 = 0\n",
    "                elif i < number_of_lines:\n",
    "                    flag1 = 1\n",
    "                if j == number_of_lines:\n",
    "                    flag2 = 0\n",
    "                elif j < number_of_lines:\n",
    "                    flag2 = 1\n",
    "\n",
    "        elif flag2 == 2:\n",
    "            #print(\"here5\")\n",
    "            while(flag1 == 1 and flag3 == 1):\n",
    "                try:\n",
    "                    first1 = in1[i].split(\",\")\n",
    "                except:\n",
    "                    flag1 = 2\n",
    "                    continue\n",
    "                try:\n",
    "                    first3 = in3[k].split(\",\")\n",
    "                except:\n",
    "                    flag3 = 2\n",
    "                    continue\n",
    "\n",
    "                #if current word is same in both files \n",
    "                if first1[0] == first3[0]:\n",
    "                    getbyte = first1[1]\n",
    "                    p1.seek(int(getbyte))\n",
    "                    posting1 = p1.readline()\n",
    "                    posting1 = posting1[0:len(posting1)-1].split(\",\")\n",
    "\n",
    "                    getbyte = first3[1]\n",
    "                    p3.seek(int(getbyte))\n",
    "                    posting3 = p3.readline()\n",
    "                    posting3 = posting3[0:len(posting3)-1].split(\",\")\n",
    "\n",
    "\n",
    "                    posting1 = Decode(posting1)\n",
    "                    posting3 = Decode(posting3)\n",
    "\n",
    "                    output_posting = MergePostings(posting1, posting3)\n",
    "                    \n",
    "                    output_posting = Encode(output_posting)\n",
    "                    \n",
    "                    lol = [str(int) for int in output_posting]\n",
    "                    lol = \",\".join(lol)\n",
    "                    byte = output_post.tell()\n",
    "                    output_post.write(lol + \"\\n\")\n",
    "                    output_in.write(first3[0] + \",\" + str(byte) + \"\\n\")\n",
    "                    i = i + 1\n",
    "                    k = k + 1\n",
    "\n",
    "                elif min(first1[0], first3[0]) == first1[0]:\n",
    "                    getbyte = first1[1]\n",
    "                    p1.seek(int(getbyte))\n",
    "                    posting = p1.readline()\n",
    "                    byte = output_post.tell()\n",
    "                    output_post.write(posting)\n",
    "                    #print(first1[0] + \",\" + str(byte) + \"\\n\")\n",
    "                    output_in.write(first1[0] + \",\" + str(byte) + \"\\n\")\n",
    "                    i = i + 1\n",
    "                else:\n",
    "                    getbyte = first3[1]\n",
    "                    p3.seek(int(getbyte))\n",
    "                    posting = p3.readline()\n",
    "                    byte = output_post.tell()\n",
    "                    output_post.write(posting)\n",
    "                    #print(first2[0] + \",\" + str(byte) + \"\\n\")\n",
    "                    output_in.write(first3[0] + \",\" + str(byte) + \"\\n\")\n",
    "                    k = k + 1\n",
    "\n",
    "                if i == number_of_lines:\n",
    "                    flag1 = 0\n",
    "                elif i < number_of_lines:\n",
    "                    flag1 = 1\n",
    "                if k == number_of_lines:\n",
    "                    flag3 = 0\n",
    "                elif k < number_of_lines:\n",
    "                    flag3 = 1\n",
    "\n",
    "        elif flag1 == 2:\n",
    "            #print(\"here5\")\n",
    "            while(flag3 == 1 and flag2 == 1):\n",
    "                try:\n",
    "                    first3 = in3[k].split(\",\")\n",
    "                except:\n",
    "                    flag3 = 2\n",
    "                    continue\n",
    "                try:\n",
    "                    first2 = in2[j].split(\",\")\n",
    "                except:\n",
    "                    flag2 = 2\n",
    "                    continue\n",
    "\n",
    "                #if current word is same in both files \n",
    "                if first3[0] == first2[0]:\n",
    "                    getbyte = first3[1]\n",
    "                    p3.seek(int(getbyte))\n",
    "                    posting3 = p3.readline()\n",
    "                    posting3 = posting3[0:len(posting3)-1].split(\",\")\n",
    "\n",
    "                    getbyte = first2[1]\n",
    "                    p2.seek(int(getbyte))\n",
    "                    posting2 = p2.readline()\n",
    "                    posting2 = posting2[0:len(posting2)-1].split(\",\")\n",
    "\n",
    "                    posting3 = Decode(posting3)\n",
    "                    posting2 = Decode(posting2)\n",
    "\n",
    "                    output_posting = MergePostings(posting3, posting2)\n",
    "                    output_posting = Encode(output_posting)\n",
    "                    lol = [str(int) for int in output_posting]\n",
    "                    lol = \",\".join(lol)\n",
    "                    byte = output_post.tell()\n",
    "                    output_post.write(lol + \"\\n\")\n",
    "                    output_in.write(first2[0] + \",\" + str(byte) + \"\\n\")\n",
    "                    k = k + 1\n",
    "                    j = j + 1\n",
    "\n",
    "                elif min(first3[0], first2[0]) == first3[0]:\n",
    "                    getbyte = first3[1]\n",
    "                    p3.seek(int(getbyte))\n",
    "                    posting = p3.readline()\n",
    "                    byte = output_post.tell()\n",
    "                    output_post.write(posting)\n",
    "                    #print(first1[0] + \",\" + str(byte) + \"\\n\")\n",
    "                    output_in.write(first3[0] + \",\" + str(byte) + \"\\n\")\n",
    "                    k = k + 1\n",
    "                else:\n",
    "                    getbyte = first2[1]\n",
    "                    p2.seek(int(getbyte))\n",
    "                    posting = p2.readline()\n",
    "                    byte = output_post.tell()\n",
    "                    output_post.write(posting)\n",
    "                    #print(first2[0] + \",\" + str(byte) + \"\\n\")\n",
    "                    output_in.write(first2[0] + \",\" + str(byte) + \"\\n\")\n",
    "                    j = j + 1\n",
    "\n",
    "                if k == number_of_lines:\n",
    "                    flag3 = 0\n",
    "                elif k < number_of_lines:\n",
    "                    flag3 = 1\n",
    "                if j == number_of_lines:\n",
    "                    flag2 = 0\n",
    "                elif j < number_of_lines:\n",
    "                    flag2 = 1\n",
    "\n",
    "        # read all files\n",
    "        while(flag1 == 1 and flag2 == 1 and flag3 == 1):\n",
    "            #print(\"here6\")\n",
    "            try:\n",
    "                first1 = in1[i].split(\",\")\n",
    "            except:\n",
    "                flag1 = 2\n",
    "                continue\n",
    "            try:\n",
    "                first2 = in2[j].split(\",\")\n",
    "            except:\n",
    "                flag2 = 2\n",
    "                continue\n",
    "            try:\n",
    "                first3 = in3[k].split(\",\")\n",
    "            except:\n",
    "                flag3 = 2\n",
    "                continue\n",
    "\n",
    "            #if current word is same in both files \n",
    "            if first1[0] == first2[0] and first2[0] == first3[0]:\n",
    "                getbyte = first1[1]\n",
    "                p1.seek(int(getbyte))\n",
    "                posting1 = p1.readline()\n",
    "                posting1 = posting1[0:len(posting1)-1].split(\",\")\n",
    "\n",
    "                getbyte = first2[1]\n",
    "                p2.seek(int(getbyte))\n",
    "                posting2 = p2.readline()\n",
    "                posting2 = posting2[0:len(posting2)-1].split(\",\")\n",
    "\n",
    "                getbyte = first3[1]\n",
    "                p3.seek(int(getbyte))\n",
    "                posting3 = p3.readline()\n",
    "                posting3 = posting3[0:len(posting3)-1].split(\",\")\n",
    "\n",
    "                posting1 = Decode(posting1)\n",
    "                posting2 = Decode(posting2)\n",
    "                posting3 = Decode(posting3)\n",
    "\n",
    "                output_posting = MergePostings(posting1, posting2)\n",
    "                output_posting = MergePostings(output_posting, posting3)\n",
    "                output_posting = Encode(output_posting)\n",
    "\n",
    "                lol = [str(int) for int in output_posting]\n",
    "                lol = \",\".join(lol)\n",
    "                byte = output_post.tell()\n",
    "                output_post.write(lol + \"\\n\")\n",
    "                output_in.write(first2[0] + \",\" + str(byte) + \"\\n\")\n",
    "                i = i + 1\n",
    "                j = j + 1\n",
    "                k = k + 1\n",
    "\n",
    "            elif first1[0] == first2[0]:\n",
    "                getbyte = first1[1]\n",
    "                #print(getbyte)\n",
    "                p1.seek(int(getbyte))\n",
    "                posting1 = p1.readline()\n",
    "                posting1 = posting1[0:len(posting1)-1].split(\",\")\n",
    "\n",
    "                getbyte = first2[1]\n",
    "                p2.seek(int(getbyte))\n",
    "                posting2 = p2.readline()\n",
    "                posting2 = posting2[0:len(posting2)-1].split(\",\")\n",
    "\n",
    "                posting1 = Decode(posting1)\n",
    "                posting2 = Decode(posting2)\n",
    "\n",
    "                output_posting = MergePostings(posting1, posting2)\n",
    "                output_posting = Encode(output_posting)\n",
    "                lol = [str(int) for int in output_posting]\n",
    "                lol = \",\".join(lol)\n",
    "                byte = output_post.tell()\n",
    "                output_post.write(lol + \"\\n\")\n",
    "                output_in.write(first2[0] + \",\" + str(byte) + \"\\n\")\n",
    "                i = i + 1\n",
    "                j = j + 1\n",
    "\n",
    "            elif first1[0] == first3[0]:\n",
    "                getbyte = first1[1]\n",
    "                #print(getbyte)\n",
    "                p1.seek(int(getbyte))\n",
    "                posting1 = p1.readline()\n",
    "                posting1 = posting1[0:len(posting1)-1].split(\",\")\n",
    "\n",
    "                getbyte = first3[1]\n",
    "                p3.seek(int(getbyte))\n",
    "                posting3 = p3.readline()\n",
    "                posting3 = posting3[0:len(posting3)-1].split(\",\")\n",
    "\n",
    "                posting1 = Decode(posting1)\n",
    "                posting3 = Decode(posting3)\n",
    "                \n",
    "                output_posting = MergePostings(posting1, posting3)\n",
    "                output_posting = Encode(output_posting)\n",
    "\n",
    "                lol = [str(int) for int in output_posting]\n",
    "                lol = \",\".join(lol)\n",
    "                byte = output_post.tell()\n",
    "                output_post.write(lol + \"\\n\")\n",
    "                output_in.write(first1[0] + \",\" + str(byte) + \"\\n\")\n",
    "                i = i + 1\n",
    "                k = k + 1\n",
    "\n",
    "            elif first3[0] == first2[0]:\n",
    "                getbyte = first3[1]\n",
    "                p3.seek(int(getbyte))\n",
    "                posting3 = p3.readline()\n",
    "                posting3 = posting3[0:len(posting3)-1].split(\",\")\n",
    "\n",
    "                getbyte = first2[1]\n",
    "                p2.seek(int(getbyte))\n",
    "                posting2 = p2.readline()\n",
    "                posting2 = posting2[0:len(posting2)-1].split(\",\")\n",
    "\n",
    "                posting3 = Decode(posting3)\n",
    "                posting2 = Decode(posting2)\n",
    "                \n",
    "                output_posting = MergePostings(posting3, posting2)\n",
    "                output_posting = Encode(output_posting)\n",
    "                lol = [str(int) for int in output_posting]\n",
    "                lol = \",\".join(lol)\n",
    "                byte = output_post.tell()\n",
    "                output_post.write(lol + \"\\n\")\n",
    "                output_in.write(first2[0] + \",\" + str(byte) + \"\\n\")\n",
    "                k = k + 1\n",
    "                j = j + 1\n",
    "\n",
    "            elif min(first1[0], first2[0], first3[0]) == first1[0]:\n",
    "                getbyte = first1[1]\n",
    "                p1.seek(int(getbyte))\n",
    "                posting = p1.readline()\n",
    "                byte = output_post.tell()\n",
    "                output_post.write(posting)\n",
    "                #print(first1[0] + \",\" + str(byte) + \"\\n\")\n",
    "                output_in.write(first1[0] + \",\" + str(byte) + \"\\n\")\n",
    "                i = i + 1\n",
    "\n",
    "            elif min(first1[0], first2[0], first3[0]) == first3[0]:\n",
    "                getbyte = first3[1]\n",
    "                p3.seek(int(getbyte))\n",
    "                posting = p3.readline()\n",
    "                byte = output_post.tell()\n",
    "                output_post.write(posting)\n",
    "                #print(first1[0] + \",\" + str(byte) + \"\\n\")\n",
    "                output_in.write(first3[0] + \",\" + str(byte) + \"\\n\")\n",
    "                k = k + 1\n",
    "\n",
    "            else:\n",
    "                getbyte = first2[1]\n",
    "                p2.seek(int(getbyte))\n",
    "                posting = p2.readline()\n",
    "                byte = output_post.tell()\n",
    "                output_post.write(posting)\n",
    "                #print(first2[0] + \",\" + str(byte) + \"\\n\")\n",
    "                output_in.write(first2[0] + \",\" + str(byte) + \"\\n\")\n",
    "                j = j + 1\n",
    "\n",
    "            if i == number_of_lines:\n",
    "                flag1 = 0\n",
    "            elif i < number_of_lines:\n",
    "                flag1 = 1\n",
    "            if j == number_of_lines:\n",
    "                flag2 = 0\n",
    "            elif j < number_of_lines:\n",
    "                flag2 = 1\n",
    "            if k == number_of_lines:\n",
    "                flag3 = 0\n",
    "            elif k < number_of_lines:\n",
    "                flag3 = 1\n",
    "\n",
    "    output_in.close()\n",
    "    output_post.close()\n",
    "    p1.close()\n",
    "    p2.close()\n",
    "    p3.close()\n",
    "    index_file1.close()\n",
    "    index_file2.close()\n",
    "    index_file3.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "HOfgbiPHAf0v"
   },
   "outputs": [],
   "source": [
    "MergeIndexFiles()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ProcessQuery(query):\n",
    "    tokens = ParseText(query)\n",
    "    tokens\n",
    "    docs = {}\n",
    "    postings = open(\"inverted_index_postings.txt\", \"r\")\n",
    "    with open('inverted_index_terms.txt', 'r') as index_terms:\n",
    "        for line in index_terms:\n",
    "            term = line.split(\",\")\n",
    "            for word in tokens:\n",
    "                if word == term[0]:\n",
    "                    offset = int(term[1])\n",
    "                    postings.seek(offset)\n",
    "                    post = postings.readline()\n",
    "                    post = post.split(\",\")\n",
    "                    post = Decode(post)\n",
    "                    j = 1\n",
    "                    for i in range(post[0]):\n",
    "                        if word not in docs:\n",
    "                            docs[word] = [post[j]]\n",
    "                        else:\n",
    "                            docs[word].append(post[j])\n",
    "                        j = j + 1\n",
    "                        j = j + post[j] + 1\n",
    "                        i = i + 1\n",
    "    index_terms.close()\n",
    "    postings.close()\n",
    "    i = 0\n",
    "    list1 = []\n",
    "    for key in docs:\n",
    "        if i == 0:\n",
    "            list1 = docs[key]\n",
    "        else:\n",
    "            intersection_set = set.intersection(set(list1), set(docs[key]))\n",
    "            list1 = list(intersection_set)\n",
    "        i = i + 1\n",
    "    result = []\n",
    "    with open('docInfo.txt', 'r') as docinfo:\n",
    "        for line in docinfo:\n",
    "            info = line.split(\",\")\n",
    "            for doc in list1:\n",
    "                if doc == int(info[0]):\n",
    "                    result.append(info[1])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['clueweb12-0006wb-79-22541',\n",
       " 'clueweb12-0012wb-94-31402',\n",
       " 'clueweb12-0100tw-21-11869',\n",
       " 'clueweb12-0100tw-25-05344',\n",
       " 'clueweb12-0100tw-74-08426',\n",
       " 'clueweb12-0100tw-84-14181',\n",
       " 'clueweb12-0102wb-56-11337',\n",
       " 'clueweb12-0104wb-88-03977',\n",
       " 'clueweb12-0104wb-93-18870',\n",
       " 'clueweb12-0105wb-01-30277',\n",
       " 'clueweb12-0105wb-92-00243',\n",
       " 'clueweb12-0109wb-16-01307',\n",
       " 'clueweb12-0109wb-78-22647',\n",
       " 'clueweb12-0203wb-61-27243',\n",
       " 'clueweb12-0205wb-35-24050',\n",
       " 'clueweb12-0205wb-50-18317',\n",
       " 'clueweb12-0206wb-71-23133',\n",
       " 'clueweb12-0207wb-02-00245',\n",
       " 'clueweb12-0209wb-01-19807',\n",
       " 'clueweb12-0209wb-43-15294',\n",
       " 'clueweb12-0300tw-06-07418',\n",
       " 'clueweb12-0300tw-47-10976',\n",
       " 'clueweb12-0302wb-51-07386',\n",
       " 'clueweb12-0306wb-91-15684',\n",
       " 'clueweb12-0311wb-11-17224',\n",
       " 'clueweb12-0400tw-15-07826',\n",
       " 'clueweb12-0400tw-19-14132',\n",
       " 'clueweb12-0400tw-77-05817',\n",
       " 'clueweb12-0401wb-71-19597',\n",
       " 'clueweb12-0402wb-69-17651',\n",
       " 'clueweb12-0410wb-53-16290',\n",
       " 'clueweb12-0506wb-00-27596',\n",
       " 'clueweb12-0507wb-83-16824',\n",
       " 'clueweb12-0601wb-51-02580',\n",
       " 'clueweb12-0606wb-26-35035',\n",
       " 'clueweb12-0610wb-38-14055',\n",
       " 'clueweb12-0610wb-69-07730',\n",
       " 'clueweb12-0610wb-81-22845',\n",
       " 'clueweb12-0700wb-92-15179',\n",
       " 'clueweb12-0705wb-17-23793',\n",
       " 'clueweb12-0710wb-34-05319',\n",
       " 'clueweb12-0710wb-48-28319',\n",
       " 'clueweb12-0711wb-88-02111',\n",
       " 'clueweb12-0800tw-38-09395',\n",
       " 'clueweb12-0800tw-38-09396',\n",
       " 'clueweb12-0800tw-39-05237',\n",
       " 'clueweb12-0800tw-47-10089',\n",
       " 'clueweb12-0800tw-49-07482',\n",
       " 'clueweb12-0800tw-55-23347',\n",
       " 'clueweb12-0807wb-11-14857',\n",
       " 'clueweb12-0807wb-21-02063',\n",
       " 'clueweb12-0807wb-33-21698',\n",
       " 'clueweb12-0808wb-30-11741',\n",
       " 'clueweb12-0813wb-94-26685',\n",
       " 'clueweb12-0816wb-23-14873',\n",
       " 'clueweb12-0817wb-62-16267',\n",
       " 'clueweb12-0900tw-24-00475',\n",
       " 'clueweb12-0900tw-41-19545',\n",
       " 'clueweb12-0901wb-49-18208',\n",
       " 'clueweb12-1006wb-74-15824',\n",
       " 'clueweb12-1012wb-55-12894',\n",
       " 'clueweb12-1015wb-07-08685',\n",
       " 'clueweb12-1018wb-80-15198',\n",
       " 'clueweb12-1103wb-28-13718',\n",
       " 'clueweb12-1106wb-88-04271',\n",
       " 'clueweb12-1108wb-60-06001',\n",
       " 'clueweb12-1116wb-59-24329',\n",
       " 'clueweb12-1200tw-13-06363',\n",
       " 'clueweb12-1200tw-15-12335',\n",
       " 'clueweb12-1200tw-31-03155',\n",
       " 'clueweb12-1200tw-95-09146',\n",
       " 'clueweb12-1217wb-31-14226',\n",
       " 'clueweb12-1308wb-83-09956',\n",
       " 'clueweb12-1312wb-23-05471',\n",
       " 'clueweb12-1400tw-57-14839',\n",
       " 'clueweb12-1400tw-71-10050',\n",
       " 'clueweb12-1403wb-22-06202',\n",
       " 'clueweb12-1415wb-18-10531',\n",
       " 'clueweb12-1415wb-64-04772',\n",
       " 'clueweb12-1500tw-08-02990',\n",
       " 'clueweb12-1500tw-91-10901',\n",
       " 'clueweb12-1500wb-48-07444',\n",
       " 'clueweb12-1501wb-22-16210',\n",
       " 'clueweb12-1506wb-12-04988',\n",
       " 'clueweb12-1512wb-62-09814',\n",
       " 'clueweb12-1602wb-13-07993',\n",
       " 'clueweb12-1602wb-41-12621',\n",
       " 'clueweb12-1612wb-57-18760',\n",
       " 'clueweb12-1613wb-40-05635',\n",
       " 'clueweb12-1700tw-28-14211',\n",
       " 'clueweb12-1700wb-39-19605',\n",
       " 'clueweb12-1708wb-43-00729',\n",
       " 'clueweb12-1713wb-33-17384',\n",
       " 'clueweb12-1715wb-34-02466',\n",
       " 'clueweb12-1715wb-37-00240',\n",
       " 'clueweb12-1717wb-39-00682',\n",
       " 'clueweb12-1800tw-37-00184',\n",
       " 'clueweb12-1802wb-68-05084',\n",
       " 'clueweb12-1806wb-53-22519',\n",
       " 'clueweb12-1806wb-82-30494',\n",
       " 'clueweb12-1807wb-67-21484',\n",
       " 'clueweb12-1807wb-85-10975',\n",
       " 'clueweb12-1813wb-28-03870',\n",
       " 'clueweb12-1900wb-72-07191',\n",
       " 'clueweb12-1908wb-52-06038.html',\n",
       " 'clueweb12-1910wb-14-17711',\n",
       " 'clueweb12-1910wb-14-17715',\n",
       " 'clueweb12-1910wb-19-23405',\n",
       " 'clueweb12-1911wb-02-24306']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = 'movies fun'\n",
    "result = ProcessQuery(query)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "IR3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
